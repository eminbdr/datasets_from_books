{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "raw_dataset = pd.read_csv(r\"C:\\Users\\muham\\Downloads\\365data.csv\",quotechar='\"',skipinitialspace=True)\n",
    "dataset = raw_dataset.drop(raw_dataset.columns[[0,1]],inplace=True,axis=1)\n",
    "dataset = raw_dataset.copy(deep=True)\n",
    "\n",
    "sixth_prob = [  1,  34,  39,  45,  47,  68,  96, 102, 120, 124, 143, 153, 154, 159,\n",
    "       174, 195, 208, 217, 247, 249, 259, 260, 262, 275, 279, 281]\n",
    "\n",
    "dataset[dataset.columns[3]] = dataset[dataset.columns[3]].apply(lambda x: tuple(y.split(\" (\")[0] if \"(\" in y else y.strip(\",.()\") for y in x.split(\"), \")))\n",
    "dataset[dataset.columns[9]] = dataset[dataset.columns[9]].apply(lambda x: tuple([y.strip(\",. \") for y in str(x).split(\".,\")]))\n",
    "dataset[dataset.columns[10]] = dataset[dataset.columns[10]].apply(lambda x: tuple([y.strip(\",. \") for y in str(x).split(\".,\")]))\n",
    "dataset[dataset.columns[12]] = dataset[dataset.columns[12]].apply(lambda x: tuple(y.strip(\". \") for y in x.split(\".,\")))\n",
    "dataset[dataset.columns[13]] = dataset[dataset.columns[13]].apply(lambda x: tuple(y.strip(\". \") for y in x.split(\".,\")))\n",
    "dataset[dataset.columns[6]] = dataset[dataset.columns[6]].apply(lambda x: tuple([y.strip(\".,\") for y in x.split(\".,\")]))\n",
    "\n",
    "dataset[dataset.columns[0]], uniques = pd.factorize(dataset[dataset.columns[0]].explode())\n",
    "dataset[dataset.columns[1]] = dataset[dataset.columns[1]].map(dict(zip(sorted(dataset[dataset.columns[1]].unique()),list(range(6)))))\n",
    "dataset[dataset.columns[2]] = dataset[dataset.columns[2]].map(dict(zip(dataset[dataset.columns[2]].unique(),[3,2,4,0,1])))\n",
    "dataset[dataset.columns[4]] = dataset[dataset.columns[4]].map(dict(zip(sorted(dataset[dataset.columns[4]].unique()),[1,4,5,0,3,2])))\n",
    "dataset[dataset.columns[5]] = dataset[dataset.columns[5]].map(dict(zip(sorted(dataset[dataset.columns[5]].unique()),[7,6,5,4,3,2,1,0,-1])))\n",
    "dataset[dataset.columns[7]] = dataset[dataset.columns[7]].map(dict(zip(sorted(dataset[dataset.columns[7]].unique()),[2,3,0,1])))\n",
    "dataset[dataset.columns[8]] = dataset[dataset.columns[8]].map(dict(zip(sorted(dataset[dataset.columns[8]].unique()),[1,2,3,0,0,0])))\n",
    "dataset[dataset.columns[11]] = dataset[dataset.columns[11]].map(dict(zip(sorted(dataset[dataset.columns[11]].unique()),[1,0,-1])))\n",
    "\n",
    "temp = dataset.copy(deep=True)\n",
    "for i in [3,6,9,10,12,13]:\n",
    "    temp = temp.explode(temp.columns[i])\n",
    "\n",
    "\n",
    "weights = temp.groupby(temp.index).count()\n",
    "weights = 1/weights[weights.columns[0]]\n",
    "#add weight according to index\n",
    "temp = temp.merge(weights.rename(\"Weights\"),left_index=True,right_index=True)\n",
    "\n",
    "fail_answers_three = temp[temp.columns[3]].value_counts().index[10:].to_list()\n",
    "results = temp[temp.columns[3]].map(lambda x: x in fail_answers_three).reset_index()\n",
    "#get indeces of true values\n",
    "indeces = results[results[results.columns[1]] == True].index\n",
    "#drop rows with indeces\n",
    "temp.reset_index(inplace=True)\n",
    "temp = temp.drop(indeces,axis=0)\n",
    "temp.set_index(\"index\",inplace=True)\n",
    "\n",
    "temp_factorized = temp.copy(deep=True)\n",
    "uniques_fac = [i for i in range(6)]\n",
    "for i,u in zip([3,6,9,10,12,13],range(6)):\n",
    "    temp_factorized[temp_factorized.columns[i]], uniques_fac[u] = pd.factorize(temp_factorized[temp_factorized.columns[i]])\n",
    "\n",
    "dataset_wt = dataset.drop(dataset.columns[[3,6,9,10,12,13]],axis=1)\n",
    "\n",
    "translation = pd.read_csv(r\"C:\\Users\\muham\\Downloads\\sözlük.txt\",header=None).map(lambda x: str(x)).set_index(0).to_dict()[1]\n",
    "def translator(x):\n",
    "    return [translation[y] for y in x]\n",
    "temp_factorized.to_csv(\"temp.csv\",encoding=\"utf-8\",sep=\"$\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
